    We present an appropriate map from syntax to semantics for Jesse's
    variational-inference-through-integrals project.  The hope is for automatic
    differentiation to be correct, i.e.\ for the following cube to commute: 
    $$\begin{tikzcd}
                                                               & {\rm Syntax} \arrow[ddd, "D_t"', dotted] \arrow[rrr, "{\rm eval}", dotted] &  &                                        & {\rm Semantics} \arrow[ddd, "D_t"] \\
    {\rm Syntax} \arrow[ddd, "D_t"'] \arrow[rrr, "{\rm eval}"] \arrow[ru, "\int_X", dotted] &                                          &  & {\rm Semantics} \arrow[ddd, "D_t", dotted] \arrow[ru, "\int_X"'] &                      \\
                                                               &                                          &  &                                        &                      \\
                                                               & {\rm Syntax} \arrow[rrr, "{\rm eval}"', dotted]                    &  &                                        & {\rm Semantics}                    \\
    {\rm Syntax} \arrow[rrr, "{\rm eval}"'] \arrow[ru, "\int_X", dotted]                    &                                          &  & {\rm Semantics} \arrow[ru, "\int_X"']                    &
    \end{tikzcd}$$
    In what follows, we will name the set of syntax trees $\mathcal S$ and
    the semantic set (into which those trees are evaluated) $\frak D$.
    The diagram makes clear that symbols such as $D_t$ are overloaded: they
    act both on $\mathcal S$ and on $\frak D$.
    %
    To focus on applications, we restrict our attention to the non-dotted
    rectangle.  We shall discuss its nodes, edges, and faces, i.e.\ define
    the worlds $\mathcal S$ of syntax and $\frak D$ of semantics, construct the
    maps $D_t$ and $\int_X$ and $\text{eval}$, and check that the rectangle
    commutes. 
    
\begin{center}\large\textsc{Syntax}\end{center}
    
    \noindent\textbf{Grammar} ---
    Because we focus on the non-dotted rectangle, it suffices to describe the
    syntax of integrands.
    %
    Our integrand language includes arithmetic and (differentiated) step
    functions.  For concreteness, say we have ring operations, real numbers,
    real-type variable names, and for each natural $d$ the $d$th derivative
    $\Th{d}$ of the step function.
    %
    The grammar has base types \textsc{var},
    \textsc{smooth} (for smooth expressions), and \textsc{distr} with
    natural ``unit inclusions'' $\text{\textsc{var}}\hookrightarrow
    \text{\textsc{smooth}}$ and $\text{\textsc{smooth}}\hookrightarrow
    \text{\textsc{distr}}$; we regard the distributions as forming
    an algebra over the ring of smooth expressions, and we overload the
    ring operation symbols accordingly.  Syntactically, $\Th{d}$ has the type
    $\text{\textsc{smooth}}\to \text{\textsc{distr}}$.

    An example smooth expression is $y^2 - t x^3 - t$.  An example distribution
    is:
    $$
        \Th{0}(tx-y)\cdot\Th{0}(1-tx-ty)\cdot\Th{0}(y)\cdot\Th{0}(1-t/2-y)
        \cdot x^2 y
    $$
    Other standards conventions write $[f<g]$ for $\Th{0}(g-f)$ and $\delta$
    for $\Th{1}$.

    \textbf{Algebraic Structure} ---
    Are $(x+y)$ and $(y+x)$ the same syntax trees?  With the structure
    presented so far, the two differ.  However, it is conceptually useful to
    ignore such distinctions.  We thus redefine the set of syntax trees as the
    set of productions of the aforementioned grammar, \emph{mod the axioms for
    real vector spaces}.  This makes the set of syntax trees into a real vector
    space.  Going further, letting $\frak P$ denote the ring of polynomials on
    $t,x,y,\cdots, z$ with real coefficients, we consider the syntax trees
    as forming a $\frak P$-module called $\mathcal S$ 

    \textbf{Differentiation} ---
    The operator $D_t$ transforms syntax trees to
    syntax trees by application of the product rule, of real linearity,
    of the relation 
    $$
        D_t[{\mathcal V}] \triangleq 1~\text{if}~{\mathcal V}=t~\text{else}~0
    $$
    for \textsc{var} node $\mathcal V$,
    and of the chain rule for $\Th{d}$ with \textsc{smooth} tree $\mathcal E$:
    $$
        D_t[\Th{d}]({\mathcal E})] \triangleq \Th{d+1}({\mathcal E}) \cdot D_t[{\mathcal E}]  
    $$
    By induction, $D_t$'s action on integrand syntax trees is thus fully
    determined.  Moreover, it is a standard check (in the algebraic theory of
    \emph{derivations}) that this map is well-defined despite the 
    module relations.

\begin{center}\large\textsc{Semantics}\end{center}

    \noindent\textbf{Construction} ---
    How are we to interpret our integrand language?  We are familiar with the
    ring $\frak R$ of smooth functions on variables $t,u,\cdots,v,x,y,\cdots,z$
    whose every $d$th derivative ($0\leq d$) is polynomially bounded.  The
    interpretation of syntax trees of type \textsc{smooth} into $\frak R$ is
    standard.  We now construct an $\frak R$-module $\frak D$ of
    \emph{distributions} into which we shall interpret syntax trees of type
    \textsc{distr}.

    To make sense of this, we formally define $\frak D$ as the real vector
    space of continuous $\mathbb{R}$-linear functionals on $\frak G \subseteq
    \frak R$.  Here, $\frak G$ contains the smooth
    functions of $u,\cdots,v,x,y,\cdots z$ whose every $d$th derivative ($0\leq
    d$) is sub-gaussian.\footnote{The specifics of sub-gaussianity are
    unimportant: we just want to avoid divergent integrals.  We topologize
    $\frak G$ by insisting that every ball $\{g \in G : \sup_X L(g) < r\}$ be
    open, where $L$ ranges over polynomials of
    $u,\cdots,v,x,y,\cdots,z;d_u,\cdots,d_v,d_x,d_y,\cdots,d_z$ and $r$ is
    positive.}

    \textbf{Algebraic Structure} ---
    The relation $(r\cdot d)(f) = d(r\cdot f)$ for $r,d,g \in {\frak
    R},\frak{D},\frak{G}$ furnishes $\frak D$ with the additional structure of
    an $\frak R$-module.  In particular, since $\frak R$ contains the
    polynomials $\frak P$, we may view $\frak{D}$ as a $\frak P$-module. 

    \textbf{Differentiation and Integration} ---
    We define $D_t$'s action on $\frak D$ pointwise:
    $$
        (D_t d)(g) \triangleq \frac{\partial d(g)}{\partial t}
    $$
    We define $\int_X$'s action on $\frak D$ by the simple rule:
    %\footnote{
    %    An annoying possibility is that $\rho \notin\frak G$, 
    %    in which case the previous equation is undefined.  We may treat this
    %    general case by convolving with ever-narrowing gaussians and masking
    %    by ever-widening gaussians.  We choose not to discuss this case.
    %}
    $$
        \wrap{\int_X d}(g) = d(\rho) \int_X g
    $$

\begin{center}\large\textsc{Evaluation}\end{center}

    \textbf{Definition} ---
    We now define evaluation of syntactic integrands, i.e.\ the map
    $\text{eval}:{\mathcal S}\to{\frak D}$.  Up to applications of the $\frak
    P$-module axioms, the general form of a syntax tree is a polynomial of
    $\Th{d}$s with \textsc{smooth} coefficients and arguments.  As we know
    already how to evaluate \textsc{smooth} expressions into $\frak P$ and as
    we insist that evaluation be $\frak P$-linear, it suffices to define
    evaluation on a generic monomial of $\Th{d}$s.

    Well, we define\footnote{
        This limit exists by the regularity conditions that define the space $\frak G$ that $g$ inhabits.
    }
    $$
        \text{eval}\wrap{\prod_i \Th{d_i}(f_i)}
        \triangleq
        \wrap{
            g \mapsto
            \lim_{\epsilon\to 0^+}
            \int_X g \cdot
            \prod_i \varphi^{(d_i)}(f_i/\epsilon) 
        }
    $$
    Here, $\varphi$ is any smooth monotonic function equal to $0$ for inputs
    below $-1$, equal to $1$ for inputs above $+1$, and symmetrical in
    that $\phi(-x)+\phi(+x)=1$.\footnote{
        The specific choice of $\varphi$ doesn't matter; in fact,
        if we seek only first derivatives (so $D_t \int_X \cdots$ instead of
        $D_t^2 \int_X \cdots$), $\varphi$ doesn't even have to be smooth: it
        may linearly interpolate between $(-1,0)$ and $(+1,1)$.
        %
        Still, it's important not to mix up $\varphi_\epsilon$ with
        $\Th{0}$: though $\lim_\epsilon \int_X \varphi(x/\epsilon)^2 g =
        \lim_\epsilon \int_X \varphi(x/\epsilon) g$ for $g\in \frak G$, we
        have $\wrap{\Th{0}(x)}^2 \neq \Th{0}(x)$ as syntax trees.
    }
    
    \textbf{Examples} ---
    For convenience, we will write $\varphi_\epsilon(\cdot)$ for
    $\varphi(\cdot/\epsilon)$ and $\varphi_0(\cdot)$ for an actual step
    function from $\RR$ to $\RR$.  Then one may check that 
    $$
        \text{eval}\wrap{\Th{0}(f_0)\Th{0}(f_1)\Th{0}(f_d)}
        =
        \wrap{
            g \mapsto
            \int_X g \cdot \varphi_0(f_0)\varphi_0(f_1)\varphi_0(f_d)
        }
    $$
    Likewise, for $0\leq d$ one may check that
    $$
        \text{eval}\wrap{\wrap{\Th{0}(f)}^{d+1}\Th{1}(f)} 
        =
        \text{eval}\wrap{\Th{0}(f)} / (d+1)
    $$
    For coprime polynomials $f_0, f_1$ one may check that
    $$
        \text{eval}\wrap{\Th{1}(f_0\cdot f_1)\Th{0}(f_0)} 
        =
        \text{eval}\wrap{\Th{1}(f_1)\Th{0}(f_0)} 
        +
        \text{eval}\wrap{\Th{0}(f_0)}/2 
    $$

\begin{center}\large\textsc{Correctness}\end{center}

    \textbf{of Automatic Differentiation} ---
    We check that evaluation and differentiation commute (front square of
    the cubical diagram), i.e.\ that:
    $$
        \text{eval}\circ D_t 
        =
        D_t\circ \text{eval} 
    $$

    Syntax trees are generated by: real linear combinations, \textsc{var}
    nodes, $\Th{d}(\cdot)$, and multiplication.  To check commutativity, we
    induct on syntax trees so that we need only check commutativity for each of
    these generators.

    The check for real linearity follows by
    $\text{eval}$'s $\frak P$-linearity.  The check for \textsc{var}
    nodes follows from Leibniz's rule for indefinite integrals of smooth
    functions.  The check for $\Th{d}(f)$ follows formally from the
    definitions of $D_t$ and $\text{eval}$.  

    Finally, we check commutativity on products.  It suffices by $D_t$ and
    $\text{eval}$'s real linearity to check this on any real linear basis,
    for instance on the monomial products of $f$s and $\Th{d}(f)$s for
    polynomials $f$.  We finish by writing out definitions.  In order to avoid
    annoying notation, we illustrate this for a specific product; no new ideas
    are needed for the generic case.
    \begin{align*}
        &~(\text{eval}\circ D_t)\wrap{
            \Th{2}(f)
            \cdot
            \Th{3}(h)
        }(g)
        \\
        =
        &~\lim_{\epsilon\to 0^+}
            \int_X g \cdot
            \varphi_\epsilon^{(3)}(f) f^\prime \varphi_\epsilon^{(3)}(h)
            +
            \varphi_\epsilon^{(2)}(f) \varphi_\epsilon^{(4)}(h) h^\prime
        \\
        =
        &~-\lim_{\epsilon\to 0^+}
            \int_X g^\prime \cdot
            \Th{2}(f)
            \cdot
            \Th{3}(h)
        \\
        =
        &~(D_t \circ \text{eval})\wrap{
            \Th{2}(f)
            \cdot
            \Th{3}(h)
        }(g)
    \end{align*}
    The middle step applies integration by parts; the flanking
    steps are definitions.
    
    \textbf{of Switching Limits} ---
    We check that integration and differentiation commute on inputs
    $\text{eval}(d) = \wrap{g \mapsto \int_X g \cdot \prod_i \varphi^{d_i}(f_i)}$.
    This follows formally:\footnote{
        We need not invoke any theorems of calculus!  In fact, this
        subsection follows for free since all the hard work was dome in
        defining things and in checking that $D_t$ and $\text{eval}$ commute.
    }
    \begin{align*}
        &~\wrap{D_t \circ \int_X}(d)(g) 
        \\
        = 
        &~\frac{\partial}{\partial t} \wrap{
            \int_X \prod_i \varphi^{d_i}(f_i)
            \cdot \int_X g
        } 
        \\
        = 
        &~\wrap{
            \frac{\partial}{\partial t} \int_X \prod_i \varphi^{d_i}(f_i)
        } \cdot \int_X g
        \\
        =
        &~\wrap{\int_X \circ D_t}(d)(g) 
    \end{align*}
    We used that $g\in\frak G$ does not depend on $t$.

